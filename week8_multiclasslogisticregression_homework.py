# -*- coding: utf-8 -*-
"""Week8_MultiClassLogisticRegression_Homework.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BgcK8447K4wq0hUSPjgZfbyYekGPvoPK

# Week 8 Multi-Class Logistic Regression - Student Performance Analysis

## Learning Objectives:
* Understand multiclass classification
* Make predictions using multiclass classification
* Applying Machine Learning Process

## Dataset

 In this notebook, we will work on a Student Performance dataset and build a multi-class logistic regression model to predict student grade classes based on various academic and personal factors.

 The dataset contains information about student demographics, study habits, support systems, and extracurricular activities. Our goal is to predict the grade class (A, B, C, D, F) that a student will achieve based on these factors.

The dataset features include:
 - **Age**: Student's age (15-18 years)
 - **Gender**: Student's gender (0=Female, 1=Male)
 - **Ethnicity**: Student's ethnic background (0-3 categories)
    - 0: Caucasian
    - 1: African American
    - 2: Asian
    - 3: Other

 - **ParentalEducation**: Level of parental education (0-4 levels)
    - 0: None
    - 1: High School
    - 2: Some College
    - 3: Bachelor's
    - 4: Higher

 - **StudyTimeWeekly**: Weekly study time in hours, ranging from 0 to 20.
 - **Absences**: Number of absences during the school year, ranging from 0 to 30.
 - **Tutoring**: Tutoring status, where 0 indicates No and 1 indicates Yes.
 - **ParentalSupport**: The level of parental support, coded as follows:
    - 0: None
    - 1: Low
    - 2: Moderate
    - 3: High
    - 4: Very High

 - **Extracurricular**: Participation in extracurricular activities, where 0 indicates No and 1 indicates Yes.
 - **Sports**: Participation in sports, where 0 indicates No and 1 indicates Yes.
 - **Music**: Participation in music activities, where 0 indicates No and 1 indicates Yes.
 - **Volunteering**: Participation in volunteering, where 0 indicates No and 1 indicates Yes.
 - **GPA**: Grade Point Average on a scale from 2.0 to 4.0, influenced by study habits, parental involvement, and extracurricular activities.

 The target variable is **GradeClass** with 5 possible values:
 - **0**: Grade 'A' (GPA >= 3.5)
 - **1**: Grade 'B' (3.0 <= GPA < 3.5)
 - **2**: Grade 'C' (2.5 <= GPA < 3.0)
 - **3**: Grade 'D' (2.0 <= GPA < 2.5)
 - **4**: Grade 'F' (GPA < 2.0)
   
   
 Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a **TODO**.
"""

from google.colab import files
uploaded = files.upload()

"""## Create Multiclass Logistic Regression Model

The target for your model is **GradeClass**. You will predict which grade a student will achieve based on their academic and personal characteristics using multiclass logistic regression. The reason we use multiclass classification for this problem is becuase our target variable has more than 2 classes, which is different from the binary logistic regression you learned about in Week 6.

This week, we won't give you all of the individual steps that you need to take in the code. It is up to you to determine the right steps to take based on what you've learned throughout the 100 Level.

All of your model building will use the ```student_performance_train_data.csv``` data included. You'll use ```student_performance_test_data.csv``` later on.

Here are the recommended steps:
1. Perform EDA
2. Prepare the data for machine learning, including any data cleaning or feature engineering.
3. Train a Multiclass Logistic Regression model.
4. Assess the model's performance using accuracy metrics that you've learned about.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("student_performance_train_data.csv")

"""**EDA**"""

df.head()

df.describe()

df.isnull().sum()

"""**Data Preparation**"""

df['GradeClass'].value_counts().plot(kind='bar')

"""Because this does not look like a normal distribution and our response variable is not binary, we will need to train a multi class logistic regression model to calculate the probability that each repsonse will fit in one of these classes to determine which class each submission will fall into."""

plt.figure(figsize=(10,6))
sns.heatmap(df.corr())

"""Seeing GPA and Absenses as the strongest indicators of Grade Class. Also seeing potential multicollienarity between Absenses and GPA to investigate. Study time, tutoring, and parental support also look like potential indicators of GradeClass."""

df = pd.get_dummies(df, drop_first=True)

X = df.drop("GradeClass", axis=1)
y = df["GradeClass"]

"""Apply a scaler for the variables because we have so many and they all have different ranges and distributions"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""**Train the multiclass logistic regression model**

Using the same sample size and random seed from last week's regression homework btu can adjust if needed.
"""

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(multi_class="multinomial", solver="lbfgs", max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_val)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("Accuracy is", accuracy_score(y_val, y_pred))
print(classification_report(y_val, y_pred))
sns.heatmap(confusion_matrix(y_val, y_pred))

"""**Assessing model performance on test data set**"""

test_df = pd.read_csv("student_performance_test_data.csv")
test_df.head()

"""need to adjust test file to have same exact format as training data"""

id_col = "StudentID"
target_col = "GradeClass"

has_labels = target_col in test_df.columns
y_test = test_df[target_col] if has_labels else None

cols_to_drop = [c for c in [id_col, target_col] if c in test_df.columns]
X_test_raw = test_df.drop(columns=cols_to_drop)

"""Create our new testing set"""

X_test = X_test_raw.reindex(columns=X_train.columns, fill_value=0)

"""Confrim same scaler as training set"""

try:
    X_test_input = scaler.transform(X_test)
except NameError:
    X_test_input = X_test

"""Predict!!!!"""

y_test_pred = model.predict(X_test_input)
proba = None
if hasattr(model, "predict_proba"):
    proba = model.predict_proba(X_test_input)

results = pd.DataFrame({
    id_col: test_df[id_col],
    "PredictedGradeClass": y_test_pred
})
display(results.head(10))

"""## Creating a Submission File

Now that you'be created your model, you'll turn in predictions for the students listed in ```student_performance_test_data.csv```. You will make your grade predictions with your model and then output a dataframe that looks something like this:

|StudentID|PredictedGrade|
|---------|--------------|
|1001     |2             |
|1002     |1             |
|1003     |4             |

Finally, you'll use the [```DataFrame.to_csv()``` method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html) to save the dataframe to a CSV file. You need to make sure the index parameter is set to False, otherwise you will add an extra column to our CSV.
"""

submission.to_csv("student_submission.csv", index=False)
print("Submission file saved as student_submission.csv")

"""## Open Questions
1. **Model Evaluation**: Which evaluation metric (accuracy, precision, recall, F1-score, ROC-AUC) is most important for this student performance prediction problem? Justify your answer.
2. **Feature Importance**: Which feature in your model is most important for predicting student grade classes, and why?
3. **More Data**: Based on your modeling work so far, what other data points do you think will improve model accuracy? And, are there any user data points you would hesitate to use in a real-world scenario?

1. While typically accuracy is the most important, because there is an imbalance of students in each Grade Class, I believe and F score is the best. As we applied a scaler and fit all the predictors, an F statisctic is the best measure of both accuracy and precision.
2. GPA appeared to be the most important feature, which matches my initial hypothesis from EDA.
3. Exam scores could definitely help, as well as homework submission rate.

## THE END, WELL DONE!

## Submission

Download completed **Week8_MultiClassLogisticRegression_Homework.py** and **output.csv** and commit to your Github repo you shared with the faculty.
"""