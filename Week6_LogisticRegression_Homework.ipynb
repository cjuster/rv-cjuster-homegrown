{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d11dd1d4-4d4c-431e-a871-04020eef778f",
        "_uuid": "ccef06a134f4426aae32e1e69d9e9cead36fe088",
        "id": "GYsy7olxmy5f"
      },
      "source": [
        "## Week6 LogisticRegression\n",
        "In week 6, we've covered:\n",
        "* Logistic regression\n",
        "* Imbalanced Data Sets\n",
        "\n",
        "Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a **TODO**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "innpHcZzmy5g"
      },
      "source": [
        "Upload **Week6_LogisticRegression_Homework.ipynb**, **train.csv** and **test.csv** to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RhSSEroGuFCV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Dvs1aJmy5k"
      },
      "source": [
        "**TODO**: Replace **`YourFolderName`**  below with the folder name on your google drive where you put the `housing.csv` file. Run the cell, check if `train.csv` and `test.csv` is listed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o-bCYuGmy5k"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/My\\ Drive/Homegrown_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtzSDudV3kur"
      },
      "source": [
        "Alternative method to upload if mounting drive doesn't work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "_RJ4wDz10q2G",
        "outputId": "07688257-24da-4b19-e92b-3fd53c2e8b9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eaed2b09-e43e-4b7c-b2c0-b22622fb9f5a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eaed2b09-e43e-4b7c-b2c0-b22622fb9f5a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "284e99a4-b5d3-4950-bc29-35217aabccaa",
        "_uuid": "3d99c2f6dbb4a9cb7147b004708f38765ca74b77",
        "id": "O-zF2PHCmy5n"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP2ad8ompQaE"
      },
      "source": [
        "### E-commerce Website Conversion Prediction Dataset\n",
        "\n",
        "#### Overview\n",
        "This dataset contains user session data from an e-commerce website, designed to predict whether a visitor will convert (make a purchase) during their session. This is a classic **binary classification problem** with **significant class imbalance** - only about 5% of visitors actually convert.\n",
        "\n",
        "### Dataset Features\n",
        "\n",
        "#### Target Variable\n",
        "- **`converted`**: Binary target variable (0 = No conversion, 1 = Conversion)\n",
        "  - **Class imbalance**: ~95% non-conversions, ~5% conversions\n",
        "  - This imbalance makes it a perfect dataset for practicing sampling techniques\n",
        "\n",
        "### Features\n",
        "\n",
        "#### User Demographics\n",
        "- **`age`**: User's age in years (18-75)\n",
        "- **`income`**: User's annual income in USD\n",
        "\n",
        "#### Session Characteristics\n",
        "- **`session_id`**: Unique identifier for each session\n",
        "- **`device_type`**: Device used to access the site (`desktop`, `mobile`, `tablet`)\n",
        "- **`traffic_source`**: How the user found the website (`organic`, `paid_search`, `social`, `email`, `direct`, `referral`)\n",
        "- **`pages_viewed`**: Number of pages viewed during the session\n",
        "- **`session_duration_seconds`**: Time spent on the site in seconds\n",
        "- **`day_of_week`**: Day of the week (0 = Monday, 6 = Sunday)\n",
        "- **`previous_visits`**: Number of previous visits to the site\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ecc10e6-f77d-40ad-9a0a-5c8e7881e822",
        "_uuid": "d8ded7bcb480f74574cb0174f410e25e69e09046",
        "id": "nfATEd2tmy5u"
      },
      "source": [
        "## 2. Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TJ5GZAWDrxQ0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# TODO: Display the shape of the training data\n",
        "# TODO: Print the number of samples and features\n",
        "# TODO: Show the first 5 rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "f6QmkEIMsgUO"
      },
      "outputs": [],
      "source": [
        "# TODO: Display data types and non-null counts\n",
        "# TODO: Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a0VpfpJ4spMV"
      },
      "outputs": [],
      "source": [
        "# TODO: Calculate the conversion rate\n",
        "# TODO: Display value counts for the target variable (converted)\n",
        "# TODO: Show the percentage distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cM09RxRgsuSs"
      },
      "outputs": [],
      "source": [
        "# TODO: Show summary statistics for numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xna-7_d4sx-y"
      },
      "outputs": [],
      "source": [
        "# TODO: For each categorical column, display:\n",
        "#       - Number of unique values\n",
        "#       - Value counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iEp6Hm4uIf9"
      },
      "source": [
        "## 3. Baseline Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lGOSNPAzuLeM"
      },
      "outputs": [],
      "source": [
        "# TODO: Create X_train and y_train from train_data (drop 'converted' and 'session_id')\n",
        "# TODO: Create X_test and y_test from test_data (drop 'converted' and 'session_id')\n",
        "# TODO: Print shapes and conversion rates for both datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "G4Elxd0xuSOT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# TODO: Create encoded copies of X_train and X_test\n",
        "# TODO: For each categorical column, fit LabelEncoder on training data\n",
        "# TODO: Transform both training and test data using the same encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uXcgk9pZufjL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# TODO: Create a StandardScaler instance\n",
        "# TODO: Fit the scaler on X_train_encoded and transform both datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "i0-S9ZgMvKkf"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "baseline_model = LogisticRegression(\n",
        "    random_state=42,\n",
        "    max_iter=1000  # Increase max iterations to ensure convergence\n",
        ")\n",
        "\n",
        "# TODO: Fit the model on X_train_scaled and y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HBRwS3UtvwjK"
      },
      "outputs": [],
      "source": [
        "# TODO: Use the baseline model to make predictions on X_test_scaled\n",
        "# TODO: Compare predicted vs actual conversion counts and rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3oKF8vWwHzv"
      },
      "source": [
        "## 4. Baseline Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8APHvrdrvyvg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# TODO: Calculate accuracy, precision, recall, and F1-score for the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HeGI_QHUwLiT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# TODO: Generate and display the confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KmPaIKzwsNO"
      },
      "source": [
        "How is the baseline model's performing?\n",
        "\n",
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgDJWwovxlDM"
      },
      "source": [
        "## 5. Addressing the Class Imbalnce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZRHbbCEwSpl",
        "outputId": "d5f69f3a-66cb-4a4b-c7ba-34b6a3d8314b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XbKzG8Nx6Ke",
        "outputId": "16df30ad-d036-4063-a829-11ab43da75e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RANDOM OVERSAMPLING ===\n"
          ]
        }
      ],
      "source": [
        "print(\"=== RANDOM OVERSAMPLING ===\")\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# TODO: Apply fit_resample to X_train_scaled and y_train\n",
        "# TODO: Print the before/after sizes and class distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAPy1hm1yEXX",
        "outputId": "fd285e4b-e502-4ea7-8ed1-1c4564873d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RANDOM UNDERSAMPLING ===\n"
          ]
        }
      ],
      "source": [
        "print(\"=== RANDOM UNDERSAMPLING ===\")\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# TODO: Apply fit_resample to X_train_scaled and y_train\n",
        "# TODO: Print the before/after sizes and class distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP5BfZHbx8rR",
        "outputId": "8cc04b8b-f7c3-486d-94e3-bd45ac49989f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SMOTE OVERSAMPLING ===\n"
          ]
        }
      ],
      "source": [
        "print(\"=== SMOTE OVERSAMPLING ===\")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# TODO: Apply fit_resample to X_train_scaled and y_train\n",
        "# TODO: Print the before/after sizes and class distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QeftYDfVyBSh"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a comparison table showing the dataset sizes and class distributions\n",
        "# TODO: Display method name, total size, class 0 count, class 1 count, and balance ratio\n",
        "# This helps visualize the effect of each sampling technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI3xHoV2yW5O"
      },
      "source": [
        "## 6. Balanced Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti172TMFyIPR",
        "outputId": "8d401586-3c44-4625-cca5-fe0bc985efd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TRAINING MODEL WITH RANDOM OVERSAMPLING ===\n"
          ]
        }
      ],
      "source": [
        "print(\"=== TRAINING MODEL WITH RANDOM OVERSAMPLING ===\")\n",
        "\n",
        "model_ros = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# TODO: Train the model on X_train_ros and y_train_ros\n",
        "# TODO: Make predictions on X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8gKxnbGyebh",
        "outputId": "76bad3a4-4e29-49a3-dc89-43f62094d43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TRAINING MODEL WITH RANDOM UNDERSAMPLING ===\n"
          ]
        }
      ],
      "source": [
        "print(\"=== TRAINING MODEL WITH RANDOM UNDERSAMPLING ===\")\n",
        "\n",
        "model_rus = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# TODO: Train the model on X_train_rus and y_train_rus\n",
        "# TODO: Make predictions on X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhI3j3jxybde",
        "outputId": "77fb170e-ec05-4d47-a19d-14b647e3f0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TRAINING MODEL WITH SMOTE ===\n"
          ]
        }
      ],
      "source": [
        "print(\"=== TRAINING MODEL WITH SMOTE ===\")\n",
        "\n",
        "model_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# TODO: Train the model on X_train_smote and y_train_smote\n",
        "# TODO: Make predictions on X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rVD6VoMXydBQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# TODO: Calculate accuracy, precision, recall, F1-score, and ROC-AUC for all models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kk6sJ5Ry04x"
      },
      "source": [
        "Compare the model performance. What model performs the best?\n",
        "\n",
        "**TODO**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0I-OcT9Gmy66",
        "ayUFhXfYmy67"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
